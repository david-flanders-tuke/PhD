for monitors

# Field experiment aim
The aim of this repository is to provide instructions for carrying out a workshop which will evaluate researcher groups (5-7ppl) for their 'group efficiency index' (as defined by Ostrom, Pareto, Nash, et al).  This field experiment will evaluate research groups for their efficiency to produce collaborative research products for diverse marketplaces (commons, open access, proprietary, etc. The objectives of this behavioural economics field experiment are:
  1. empower researcher to agree the shared value they will derive by declaring their prefered maketplaces for research outputs;
  2. engender research organisations to keep their marketplace outputs accountable and meritable, esp University promotions; and
  3. enable research funding organisations to evaluate the optimal use of common pool resources, e.g. ARC taxpayer funded grants to researchers.  

[If you are interested in running this experiment and privately sharing your data to generate 'researcher efficiency ranks' please contact the COKI Lab at Curtin University](https://github.com/david-flanders-tuke/PhD/blob/main/about.md).  NB All data pertaining to individual researchers and/or identifable research groups will be kept private under correspnding legislation.

## Invitation to experiment
We would humbly invite field experiment facilitators, esp University administrators:
 - [x] librarians, commercialisation and other University administrative centres responsible for calculating research value;
 - [x] postgraduate students and local labs wanting an insight into optimal research group collaboration evaluation,
 - [x] research funding councils and other research grant funding bodies who would like to evaluate how best to enable optimal use of reserch funding grants; and
 - [x] publishers looking to support their customers with the marketplaces for their research outputs.

### On this page: what you'll need to run the field experiment
 - [x] purpose of the field experiment and supporting literature review;
 - [x] methodology of field experiment and participation requirements;
 - [x] administering the field experiment to participants on the day; 
 - [x] analysis of the data generated from the field experiment;
 - [x] delivery of results from field experiment and ethical implications; and
 - [x] metadata to support the field experiment.

## [Experiment purpose](https://github.com/david-flanders-tuke/PhD/blob/main/theory.md)
The resulting data which this workshop provides, is an index of research groups and their statistical 'efficiency value' as originally calculated by Ostrom et al which resulted in the 2009 Noble Prize in Economic Sciences.  The game theory methods used in this experiment calculate the optimal value which can be acheived by a group of researchers producing research objectcs for commons marketplaces.

### Frequently Asked Questions (FAQ)
*Who derives value from this experiment?*
 - [ ] How many people are required for this experiment? - 5-7 people per workshop group, with each member of the group being familiar with the other researchers in the gorup, e.g. ideally discplinary researchers who work in similar subject areas.
 - [ ] What is the value which research groups will gain by participating in this experiment? - each researcher will be categorised into their preferred marketplace type with a resulting value for the level of efficiency they achieve in playing the group game.
 - [ ] What value will research organisations (like Universities) gain by encouraging their researchers to participate in this workshop-experiment? - Making researcher expectations explicit enables clear expecations for measuring outcomes, both promotion and sanction.
 - [ ] Why should research funding coucils care about the outcomes of these experiments and the implications it has for taxpayer funded research grants? - researcher's spending taxpayer funds are obliged to define how their efforts will benefit the taxpayer and how they expect their preferrred marketplace to measure value.

*What value is manifested?*
 - [ ] What is the most efficient way to use taxpayer funds like the Australian Research Council's grants (aka common funding pools)? - Researcher's spending taxpayer funds are obliged to achieve value for the investments they receive: this experiment provides trajectories for how value can be optimised.
 - [ ] How can industry derive value from the R&D produced by scholars? - measuring scholarly outputs via a range of marketplaces enables researchers (and their funders) to report on the expected value which will be achieved from the declared research ouputs.

*Why does the experiment evaluate researchers as groups (vs individual research rank like h-index)?*
 - [ ] What are the theoretical foundations for ranking research groups in terms of their value, efficiency and marketplace type? - Behavioural economics and socioeconomics researchers (aka new institutional economics) have pioneered new field experiment methods for evaluating the institutional policies which can demonstrably enhance collective action marketplaces like taxpayer funded research grants.
 - [ ] Why should we ask researcher to self-evaluate their performance as a collective group?  Nash, Pareto and Ostrom have provided game-theory methods which enable the measurement of collective action to achieve optimal efficiency, e.g. researchers have an obligation to taxpayers to project the marketplace value they will be able to achieve in producing research products.

*How are the results of the field experiment communicated?* 
 - [ ] How can researchers trust that the data resulting from this experiment will not adversly affect their carreer?
 - [ ] What implications (call to action) are derived from each experiment? - Penidng the choice of experiment participants, the resulting analysis index from each workshop will result in a ranking for how efficient the collective action of each group is which can inform the value a research group has within an insitutional or disciplinary context.
 - [ ] Who will evaluate the experimental data and how will it be shared? - Individual consultation with each group member will take place post-workshop to provide qualitative analysis for the reasons behind each strategic decision.  If the group decides not to share their collective efficiency rank, individual's will be provided insight on their personal preferences for the types of marketplaces they prefer for their research.
 - [ ] Does the efficiency index compare research groups with one another competitively? - ["There are no panaceas!"](https://www.pnas.org/content/104/39/15181)

*Where and when does the group experiment take place?*
TBD
 - [ ] Where: Virtual vs Real-Lyf?
 - [ ] When: prep and post timelines

Katie:
 - timeliine for ethics
 - if low risk embarrassment - information sheet for participants? - you will be working with others - tick box that they have read it: "I am aware I will be participating and sharing my ideas with others in my group" - they can't compain that they didn't know this would be happening.

## [Experiment facilitation](https://github.com/david-flanders-tuke/PhD/blob/main/methodology.md)
 - [ ] [Invites to participants and required experimental permissions](https://github.com/david-flanders-tuke/PhD/blob/main/participants.md)
 - [ ] Instruction for administering the experiment by a monitor
 - [ ] Post experiment survey and interviews
 - [ ] Data collective from experiment and statistical interpretation
 - [ ] Experimental results and recommendations

Katie:
 - recruitment invitation nees to be a range of people and why it is important to have that wider group 
 - gender equality - 
 - disciplinary but bound together around a common bond.
 - Aboriginal and/or Torres Straight Islanders researchers would require full ethics approval: Maori researchers have said it is not their's to share.
 - Katie to send research on aborginal and torres straight islanders.
 - 

## [Experiment data analysis](https://github.com/david-flanders-tuke/PhD/blob/main/dataset.md)
The experiment, will result in two datasets: 
 - [ ] (a) quantitative statistical prediction for the liklihood of group optimisation: each experimental group will be categorised according to the "bids" they put forward in each round of the game. The analysis of the group participation will categorise each group into which kind of marketplace they prefer their research to engender: Pareto optimal (work collaboratively to optimise taxpayer funds), Nash equilibrium (contractually divide up funds) and/or tragedy of commons (keep their research to themselves).
 - [ ] (b) qualitative interview analysis of individual's survey data on social-behavioural decision making: after the game-experiment a transcribed interview with each participant will take place, which will go through each round of the game and the scores they provided to evaluate their individual (internal behavioural) decision model. The original framework for the model is a three layer onion: individual value, shared group value and perceived payoff value. 

The evaluation for (a) and (b) datasets as custom insights for University and Research Council insights into each research group could include:
 1. Understanding for the values which each group of discipline researchers have for either sharing their work and/or collaborating with other researchers
 2. Categorisation of research groups in terms of their liklihood to collaborate with other interdiscplinary research groups
 3. Wider understanding for the types of marketplaces which researchers want their research exposed to and how researcher expect value to be generated by their research being shared.

## [Experiment approvals](https://github.com/david-flanders-tuke/PhD/blob/main/ethic.md)
The following list of documents provide evidence by Curtin University for conduting a research experiment on humans as part of PhD research:
 - [x] Ethics approval for human experimentation aka embarrassing behaviour during a game-like workshop
 - [ ] To share or not to share?!  How our data can help Curtin University build a larger map of scholarly knowledge marketplaces.

Other related documents for purposes of transparency (not required for experiment as workshop)
 - [x] Research Data Managmeent Plan
 - [x] Research Integrity Training

## Experiment metadata
 - [ ] [Who's who in the zoo](https://github.com/david-flanders-tuke/PhD/blob/main/about.md)
 - [ ] [Bibliography](https://github.com/david-flanders-tuke/PhD/blob/main/bibliography.md)
